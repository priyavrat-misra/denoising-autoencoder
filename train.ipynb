{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "0e0d1c7ef0f381ce9c31735005e25185fd13b9c57d8e85878ff9ff982cb55e39"
        }
      }
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyRpwMqjx1Q3"
      },
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from networks import ConvUpscaleDenoiser, ConvTransposeDenoiser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxcuy3TDx1RI"
      },
      "source": [
        "# set available device\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH2y1Rt2x1RN"
      },
      "source": [
        "# extract and transform the data\n",
        "train_set = torchvision.datasets.MNIST(\n",
        "    root='./data/',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "test_set = torchvision.datasets.MNIST(\n",
        "    root='./data/',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True, num_workers=1)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, num_workers=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghqKHsdfx1RR",
        "outputId": "2cb2f719-788b-4cb0-b88b-f9d13785f921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "conv_upscale_net = ConvUpscaleDenoiser()\n",
        "conv_upscale_net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaF7xNRBx1Rb"
      },
      "source": [
        "conv_upscale_net.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(conv_upscale_net.parameters(), lr=0.01)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=1/3, patience=3, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DBSjHLux1Rf",
        "outputId": "1727948d-8780-4d29-912f-d15cc2951af9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "noise_factor = 0.5  # for adding noise to the images\n",
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    loop = tqdm(train_loader, total=len(train_loader))\n",
        "    for batch in loop:\n",
        "        images, _ = batch\n",
        "        # add random noise to the input images\n",
        "        noisy_imgs = images + noise_factor * torch.randn(*images.shape)\n",
        "        # clip the pixels to be between 0 and 1\n",
        "        noisy_imgs = np.clip(noisy_imgs, 0, 1)\n",
        "        noisy_imgs = noisy_imgs.to(device)\n",
        "        images = images.to(device)\n",
        "        \n",
        "        outputs = conv_upscale_net(noisy_imgs)\n",
        "        loss = criterion(outputs, images)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        loop.set_description(f'Epoch [{epoch+1:2d}/{num_epochs}]')\n",
        "        loop.set_postfix(loss=train_loss)\n",
        "\n",
        "    scheduler.step(train_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83ilBoAWx1Ri"
      },
      "source": [
        "# save the model\n",
        "torch.save(conv_upscale_net.state_dict(), 'models/model-upscale_net.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBdJ3QpmdUSX",
        "outputId": "1159b6aa-5ffd-4afa-8887-481858e2b246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "# obtain one batch of test images\n",
        "images, labels = next(iter(test_loader))\n",
        "\n",
        "# add noise to the test images\n",
        "noise_factor = 0.5\n",
        "noisy_imgs = images + noise_factor * torch.randn(*images.shape)\n",
        "noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
        "noisy_imgs = noisy_imgs.to(device)\n",
        "images = images.to(device)\n",
        "\n",
        "# get sample outputs\n",
        "output = conv_upscale_net(noisy_imgs)\n",
        "# prep images for display\n",
        "noisy_imgs = noisy_imgs.cpu().numpy()\n",
        "\n",
        "# use detach when it's an output that requires_grad\n",
        "output = output.detach().cpu().numpy()\n",
        "\n",
        "# plot the first ten input images and then reconstructed images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
        "\n",
        "# input images on top row, reconstructions on bottom\n",
        "for noisy_imgs, row in zip([noisy_imgs, output], axes):\n",
        "    for img, ax in zip(noisy_imgs, row):\n",
        "        ax.imshow(np.squeeze(img), cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3faWqkTAePW3",
        "outputId": "d311192e-3487-4889-b631-6f2b94503af4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "conv_transpose_net = ConvTransposeDenoiser()\n",
        "conv_transpose_net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knBhaHxofPpy"
      },
      "source": [
        "conv_transpose_net.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(conv_transpose_net.parameters(), lr=0.01)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=1/3, patience=3, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEVm9if0fnMZ",
        "outputId": "8220d7f9-edb8-4101-dfcb-d1a9c9cbd592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "noise_factor = 0.5  # for adding noise to the images\n",
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    loop = tqdm(train_loader, total=len(train_loader))\n",
        "    for batch in loop:\n",
        "        images, _ = batch\n",
        "        # add random noise to the input images\n",
        "        noisy_imgs = images + noise_factor * torch.randn(*images.shape)\n",
        "        # clip the pixels to be between 0 and 1\n",
        "        noisy_imgs = np.clip(noisy_imgs, 0, 1)\n",
        "        noisy_imgs = noisy_imgs.to(device)\n",
        "        images = images.to(device)\n",
        "        \n",
        "        outputs = conv_transpose_net(noisy_imgs)\n",
        "        loss = criterion(outputs, images)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "        loop.set_description(f'Epoch [{epoch+1:2d}/{num_epochs}]')\n",
        "        loop.set_postfix(loss=train_loss)\n",
        "\n",
        "    scheduler.step(train_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqtH0Wh8f1wR"
      },
      "source": [
        "# save the model\n",
        "torch.save(conv_transpose_net.state_dict(), 'models/model-transpose_net.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwNQdSnyf5VY",
        "outputId": "65198c35-4e54-4339-c9aa-76ee83a8d702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "# obtain one batch of test images\n",
        "images, labels = next(iter(test_loader))\n",
        "\n",
        "# add noise to the test images\n",
        "noise_factor = 0.5\n",
        "noisy_imgs = images + noise_factor * torch.randn(*images.shape)\n",
        "noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
        "noisy_imgs = noisy_imgs.to(device)\n",
        "images = images.to(device)\n",
        "\n",
        "# get sample outputs\n",
        "output = conv_transpose_net(noisy_imgs)\n",
        "# prep images for display\n",
        "noisy_imgs = noisy_imgs.cpu().numpy()\n",
        "\n",
        "# use detach when it's an output that requires_grad\n",
        "output = output.detach().cpu().numpy()\n",
        "\n",
        "# plot the first ten input images and then reconstructed images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
        "\n",
        "# input images on top row, reconstructions on bottom\n",
        "for noisy_imgs, row in zip([noisy_imgs, output], axes):\n",
        "    for img, ax in zip(noisy_imgs, row):\n",
        "        ax.imshow(np.squeeze(img), cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}